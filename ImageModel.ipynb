{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7009ebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 00:34:24,321 - INFO - Loading datasets...\n",
      "2025-04-30 00:34:25,634 - INFO - Oversampling rare genres...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Train: 63639, Val: 7981, Test: 7963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 00:34:25,880 - INFO - Creating datasets...\n",
      "2025-04-30 00:34:25,889 - INFO - Computing class weights...\n",
      "2025-04-30 00:34:25,989 - INFO - Using device: cpu\n",
      "2025-04-30 00:34:25,993 - INFO - Initializing model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled training set: 118785 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 00:34:26,293 - INFO - Starting epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Image-based CNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 7425/7425 [1:01:49<00:00,  2.00it/s]\n",
      "Epoch 1 Validation: 100%|██████████| 499/499 [02:03<00:00,  4.02it/s]\n",
      "2025-04-30 01:38:19,892 - INFO - Positive predictions per genre: [1507. 1360. 1800. 3261. 1654. 1464. 5241. 1630.  539.  386. 3195. 1727.\n",
      " 1446. 1574.  799. 1384. 1817.  710.  468.]\n",
      "2025-04-30 01:38:19,924 - INFO - Starting epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.3927, Val Loss: 0.3540, Val F1 Macro: 0.3068, Val Accuracy: 0.8047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 7425/7425 [1:02:00<00:00,  2.00it/s]\n",
      "Epoch 2 Validation: 100%|██████████| 499/499 [02:05<00:00,  3.96it/s]\n",
      "2025-04-30 02:42:26,256 - INFO - Positive predictions per genre: [1727. 1077.  579. 3592. 1430. 1769. 6088.  713.  545.  486. 1038. 1343.\n",
      "  879. 2556.  564.  928. 2259.  579.  401.]\n",
      "2025-04-30 02:42:26,290 - INFO - Starting epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.3789, Val Loss: 0.3422, Val F1 Macro: 0.3477, Val Accuracy: 0.8321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 7425/7425 [1:02:06<00:00,  1.99it/s]\n",
      "Epoch 3 Validation: 100%|██████████| 499/499 [02:03<00:00,  4.05it/s]\n",
      "2025-04-30 03:46:36,397 - INFO - Positive predictions per genre: [1397.  663.  597. 3068. 2166. 1588. 6135. 1017.  806.  533. 1103. 1619.\n",
      " 1639. 1770.  586.  657. 1763.  944.  300.]\n",
      "2025-04-30 03:46:36,428 - INFO - Starting epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.3693, Val Loss: 0.3475, Val F1 Macro: 0.3510, Val Accuracy: 0.8311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 7425/7425 [1:02:11<00:00,  1.99it/s]\n",
      "Epoch 4 Validation: 100%|██████████| 499/499 [02:03<00:00,  4.03it/s]\n",
      "2025-04-30 04:50:52,329 - INFO - Positive predictions per genre: [1940. 1454.  536. 2966. 1523. 1253. 5663.  822.  717.  554.  884. 1211.\n",
      " 1097. 2344.  725. 1067. 1673.  998.  413.]\n",
      "2025-04-30 04:50:52,331 - INFO - Starting epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.3577, Val Loss: 0.3517, Val F1 Macro: 0.3485, Val Accuracy: 0.8322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 7425/7425 [1:02:23<00:00,  1.98it/s]\n",
      "Epoch 5 Validation: 100%|██████████| 499/499 [02:03<00:00,  4.03it/s]\n",
      "2025-04-30 05:55:20,380 - INFO - Positive predictions per genre: [1397. 1073.  567. 3052. 2151. 1253. 5667.  704.  764.  527. 1129. 1107.\n",
      "  718. 2774. 1057. 1168. 1674.  346.  298.]\n",
      "2025-04-30 05:55:20,382 - INFO - Starting epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.3438, Val Loss: 0.3509, Val F1 Macro: 0.3386, Val Accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 7425/7425 [1:02:59<00:00,  1.96it/s]\n",
      "Epoch 6 Validation: 100%|██████████| 499/499 [02:07<00:00,  3.93it/s]\n",
      "2025-04-30 07:00:26,682 - INFO - Positive predictions per genre: [2132. 1126.  573. 3091. 2280. 1202. 6413.  656.  767.  416.  963. 1030.\n",
      " 1121. 1932.  755.  914. 1611.  275.  267.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.3181, Val Loss: 0.3560, Val F1 Macro: 0.3437, Val Accuracy: 0.8353\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 07:00:27,160 - INFO - Evaluating model...\n",
      "Evaluation: 100%|██████████| 499/499 [02:06<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Model Evaluation:\n",
      "F1 Macro: 0.3567, F1 Micro: 0.4286, Accuracy: 0.8377\n",
      "Precision: 0.3104, Recall: 0.4573\n",
      "Action - F1: 0.3933, Accuracy: 0.8129\n",
      "Adventure - F1: 0.2869, Accuracy: 0.8897\n",
      "Animation - F1: 0.6636, Accuracy: 0.9629\n",
      "Comedy - F1: 0.5793, Accuracy: 0.7097\n",
      "Crime - F1: 0.2957, Accuracy: 0.7875\n",
      "Documentary - F1: 0.3643, Accuracy: 0.8146\n",
      "Drama - F1: 0.6262, Accuracy: 0.5578\n",
      "Family - F1: 0.4030, Accuracy: 0.9295\n",
      "Fantasy - F1: 0.2458, Accuracy: 0.8831\n",
      "History - F1: 0.1439, Accuracy: 0.9120\n",
      "Horror - F1: 0.4393, Accuracy: 0.8570\n",
      "Music - F1: 0.2816, Accuracy: 0.7999\n",
      "Mystery - F1: 0.1700, Accuracy: 0.7871\n",
      "Romance - F1: 0.3937, Accuracy: 0.7750\n",
      "Science Fiction - F1: 0.3054, Accuracy: 0.9105\n",
      "TV Movie - F1: 0.2342, Accuracy: 0.8984\n",
      "Thriller - F1: 0.4062, Accuracy: 0.7835\n",
      "War - F1: 0.1372, Accuracy: 0.8723\n",
      "Western - F1: 0.4077, Accuracy: 0.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ranje\\AppData\\Local\\Temp\\ipykernel_23144\\2702759428.py:292: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=f1_scores, y=all_genres, palette=\"viridis\")\n",
      "C:\\Users\\ranje\\AppData\\Local\\Temp\\ipykernel_23144\\2702759428.py:305: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=accuracy_scores, y=all_genres, palette=\"magma\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample misclassifications:\n",
      "Movie: Destruction Force\n",
      "True Genres: ['Crime']\n",
      "Pred Genres: ['Action', 'Crime', 'Drama']\n",
      "Poster Path: /hLQxmeMTmxgn4HjraPb6kkxgd9N.jpg\n",
      "\n",
      "Movie: The Perez Family\n",
      "True Genres: ['Comedy', 'Drama', 'Romance']\n",
      "Pred Genres: ['Comedy', 'Drama', 'Music', 'Romance']\n",
      "Poster Path: /jxi3UDHf86kDk5hqJxnpEMzVch2.jpg\n",
      "\n",
      "Movie: Queensrÿche: The Art of Live\n",
      "True Genres: ['Music']\n",
      "Pred Genres: ['Documentary', 'Music']\n",
      "Poster Path: /krJsYaLovn1JgkjprEu6DWFWrdh.jpg\n",
      "\n",
      "Movie: The Totenwackers\n",
      "True Genres: ['Adventure', 'Comedy']\n",
      "Pred Genres: ['Drama', 'Romance']\n",
      "Poster Path: /vj45dWwcwBlbp1COcthiJAiTN8Y.jpg\n",
      "\n",
      "Movie: 400 Against 1: A History of Organized Crime\n",
      "True Genres: ['Action', 'Crime', 'Drama']\n",
      "Pred Genres: ['Documentary', 'Drama', 'Music']\n",
      "Poster Path: /vYjpX0uLBCtjJBf42zJk4OxepPx.jpg\n",
      "\n",
      "Best image model saved to best_image_model.pth\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "all_genres = [\n",
    "    \"Action\", \"Adventure\", \"Animation\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\",\n",
    "    \"Family\", \"Fantasy\", \"History\", \"Horror\", \"Music\", \"Mystery\", \"Romance\",\n",
    "    \"Science Fiction\", \"TV Movie\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "\n",
    "logger.info(\"Loading datasets...\")\n",
    "train_df = pd.read_json(\"train_fixed_updated.json\")\n",
    "val_df = pd.read_json(\"val_fixed_updated.json\")\n",
    "test_df = pd.read_json(\"test_fixed_updated.json\")\n",
    "print(f\"Loaded Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "\n",
    "\n",
    "logger.info(\"Oversampling rare genres...\")\n",
    "rare_genres = [\"TV Movie\", \"History\", \"Mystery\", \"Adventure\", \"Fantasy\", \"Crime\", \"Music\", \"War\", \"Western\", \"Documentary\", \"Science Fiction\", \"Animation\", \"Family\"]\n",
    "oversampled_dfs = [train_df]\n",
    "for genre in rare_genres:\n",
    "    genre_df = train_df[train_df[\"genre_labels\"].apply(lambda x: x[all_genres.index(genre)] == 1)]\n",
    "    n_samples = len(train_df)//15 \n",
    "    oversampled = resample(genre_df, replace=True, n_samples=n_samples, random_state=42)\n",
    "    oversampled_dfs.append(oversampled)\n",
    "train_df_oversampled = pd.concat(oversampled_dfs)\n",
    "print(f\"Oversampled training set: {len(train_df_oversampled)} samples\")\n",
    "\n",
    "\n",
    "class MovieImageDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.df.iloc[idx][\"poster_path\"].lstrip(\"/\"))\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error loading image {img_path}: {e}\")\n",
    "            image = Image.new(\"RGB\", (224, 224), (0, 0, 0))\n",
    "        \n",
    "        labels = np.array(self.df.iloc[idx][\"genre_labels\"], dtype=np.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "image_dir = \"images/\"\n",
    "logger.info(\"Creating datasets...\")\n",
    "train_dataset = MovieImageDataset(train_df_oversampled, image_dir, train_transform)\n",
    "val_dataset = MovieImageDataset(val_df, image_dir, val_test_transform)\n",
    "test_dataset = MovieImageDataset(test_df, image_dir, val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, num_workers=0)\n",
    "\n",
    "\n",
    "class ImageMovieGenreClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=19):\n",
    "        super(ImageMovieGenreClassifier, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(in_features, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "def compute_class_weights(labels):\n",
    "    n_samples = labels.shape[0]\n",
    "    n_classes = labels.shape[1]\n",
    "    class_counts = np.sum(labels, axis=0)\n",
    "    weights = n_samples / (n_classes * class_counts)\n",
    "    for i, genre in enumerate(all_genres):\n",
    "        if genre in [\"TV Movie\", \"History\", \"Mystery\", \"Crime\", \"Music\", \"War\", \"Western\", \"Documentary\", \"Science Fiction\", \"Animation\", \"Family\"]:\n",
    "            weights[i] *= 2.5  \n",
    "    return torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "logger.info(\"Computing class weights...\")\n",
    "train_labels = np.array(train_df_oversampled[\"genre_labels\"].tolist())\n",
    "device = torch.device(\"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "class_weights = compute_class_weights(train_labels).to(device)\n",
    "np.save(\"image_class_weights.npy\", class_weights.cpu().numpy())\n",
    "\n",
    "\n",
    "class LabelSmoothingBCELoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(LabelSmoothingBCELoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        target_smooth = target * (1 - self.smoothing) + self.smoothing / 2\n",
    "        return nn.BCELoss(weight=class_weights)(pred, target_smooth)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=10, patience=3):\n",
    "    best_val_f1 = 0\n",
    "    trigger = 0\n",
    "    train_losses, val_losses, val_accuracies = [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        logger.info(f\"Starting epoch {epoch+1}/{epochs}\")\n",
    "        for i, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\")):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_losses.append(train_loss/len(train_loader))\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_preds.append(outputs.cpu().numpy())\n",
    "                val_true.append(labels.cpu().numpy())\n",
    "        \n",
    "        val_losses.append(val_loss/len(val_loader))\n",
    "        val_preds = np.concatenate(val_preds)\n",
    "        val_true = np.concatenate(val_true)\n",
    "        \n",
    "       \n",
    "        thresholds = np.arange(0.01, 0.3, 0.05) \n",
    "        best_val_preds_binary = np.zeros_like(val_preds)\n",
    "        for i, genre in enumerate(all_genres):\n",
    "            best_f1, best_thresh = 0, 0.5\n",
    "            thresh_range = thresholds if genre in [\"TV Movie\", \"History\", \"Mystery\", \"Crime\", \"Music\", \"War\", \"Western\", \"Documentary\", \"Science Fiction\", \"Animation\", \"Family\"] else np.arange(0.1, 0.6, 0.1)\n",
    "            for thresh in thresh_range:\n",
    "                preds_binary = (val_preds[:, i] > thresh).astype(int)\n",
    "                f1 = f1_score(val_true[:, i], preds_binary)\n",
    "                if f1 > best_f1:\n",
    "                    best_f1, best_thresh = f1, thresh\n",
    "            best_val_preds_binary[:, i] = (val_preds[:, i] > best_thresh).astype(int)\n",
    "        \n",
    "        val_f1_macro = f1_score(val_true, best_val_preds_binary, average=\"macro\")\n",
    "        val_accuracy = (val_true == best_val_preds_binary).mean()\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "       \n",
    "        positive_preds = np.sum(best_val_preds_binary, axis=0)\n",
    "        logger.info(f\"Positive predictions per genre: {positive_preds}\")\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}, Val F1 Macro: {val_f1_macro:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        if val_f1_macro > best_val_f1:\n",
    "            best_val_f1 = val_f1_macro\n",
    "            torch.save(model.state_dict(), \"best_image_model.pth\")\n",
    "            trigger = 0\n",
    "        else:\n",
    "            trigger += 1\n",
    "            if trigger >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Image Model: Training and Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"loss_curves_image.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(val_accuracies, label=\"Val Accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Image Model: Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"accuracy_curves_image.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return best_val_f1\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    preds, true = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Evaluation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds.append(outputs.cpu().numpy())\n",
    "            true.append(labels.cpu().numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds)\n",
    "    true = np.concatenate(true)\n",
    "    \n",
    "    thresholds = np.arange(0.01, 0.8, 0.05)\n",
    "    best_thresholds = []\n",
    "    for i, genre in enumerate(all_genres):\n",
    "        thresh_range = thresholds if genre in [\"TV Movie\", \"History\", \"Mystery\", \"Crime\", \"Music\", \"War\", \"Western\", \"Documentary\", \"Science Fiction\", \"Animation\", \"Family\"] else np.arange(0.1, 0.9, 0.1)\n",
    "        best_f1, best_thresh = 0, 0.5\n",
    "        for thresh in thresh_range:\n",
    "            preds_binary = (preds[:, i] > thresh).astype(int)\n",
    "            f1 = f1_score(true[:, i], preds_binary)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_thresh = f1, thresh\n",
    "        best_thresholds.append(best_thresh)\n",
    "    \n",
    "    preds_binary = np.zeros_like(preds)\n",
    "    for i, thresh in enumerate(best_thresholds):\n",
    "        preds_binary[:, i] = (preds[:, i] > thresh).astype(int)\n",
    "    \n",
    "    f1_macro = f1_score(true, preds_binary, average=\"macro\")\n",
    "    f1_micro = f1_score(true, preds_binary, average=\"micro\")\n",
    "    precision = precision_score(true, preds_binary, average=\"macro\")\n",
    "    recall = recall_score(true, preds_binary, average=\"macro\")\n",
    "    accuracy = (true == preds_binary).mean()\n",
    "    \n",
    "    print(f\"Image Model Evaluation:\")\n",
    "    print(f\"F1 Macro: {f1_macro:.4f}, F1 Micro: {f1_micro:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    f1_scores, accuracy_scores = [], []\n",
    "    for i, genre in enumerate(all_genres):\n",
    "        f1 = f1_score(true[:, i], preds_binary[:, i])\n",
    "        acc = accuracy_score(true[:, i], preds_binary[:, i])\n",
    "        f1_scores.append(f1)\n",
    "        accuracy_scores.append(acc)\n",
    "        print(f\"{genre} - F1: {f1:.4f}, Accuracy: {acc:.4f}\")\n",
    "    \n",
    "   \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=f1_scores, y=all_genres, palette=\"viridis\")\n",
    "    plt.xlabel(\"F1 Score\")\n",
    "    plt.ylabel(\"Genre\")\n",
    "    plt.title(\"Image Model: F1 Scores by Genre\")\n",
    "    plt.xlim(0, 1)\n",
    "    for i, score in enumerate(f1_scores):\n",
    "        plt.text(score + 0.01, i, f\"{score:.4f}\", va=\"center\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"f1_scores_image.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=accuracy_scores, y=all_genres, palette=\"magma\")\n",
    "    plt.xlabel(\"Accuracy\")\n",
    "    plt.ylabel(\"Genre\")\n",
    "    plt.title(\"Image Model: Accuracy by Genre\")\n",
    "    plt.xlim(0, 1)\n",
    "    for i, score in enumerate(accuracy_scores):\n",
    "        plt.text(score + 0.01, i, f\"{score:.4f}\", va=\"center\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"accuracy_scores_image.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "   \n",
    "    cm = confusion_matrix(true[:, all_genres.index(\"Action\")], preds_binary[:, all_genres.index(\"Action\")])\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=[\"Not Action\", \"Action\"], yticklabels=[\"Not Action\", \"Action\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Image Model: Confusion Matrix for Action\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"cm_image_action.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "   \n",
    "    errors = val_df.copy()\n",
    "    errors[\"pred_genres\"] = [np.where(pred==1)[0] for pred in preds_binary]\n",
    "    errors[\"true_genres\"] = [np.where(true==1)[0] for true in true]\n",
    "    errors[\"correct\"] = errors.apply(lambda x: set(x[\"pred_genres\"]) == set(x[\"true_genres\"]), axis=1)\n",
    "    incorrect = errors[~errors[\"correct\"]]\n",
    "    print(\"\\nSample misclassifications:\")\n",
    "    for _, row in incorrect.head(5).iterrows():\n",
    "        print(f\"Movie: {row['title']}\")\n",
    "        print(f\"True Genres: {[all_genres[i] for i in row['true_genres']]}\")\n",
    "        print(f\"Pred Genres: {[all_genres[i] for i in row['pred_genres']]}\")\n",
    "        print(f\"Poster Path: {row['poster_path']}\")\n",
    "        print()\n",
    "    \n",
    "    return preds_binary, true, best_thresholds\n",
    "\n",
    "\n",
    "logger.info(\"Initializing model...\")\n",
    "model = ImageMovieGenreClassifier().to(device)\n",
    "criterion = LabelSmoothingBCELoss(smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n",
    "\n",
    "print(\"Training Image-based CNN\")\n",
    "best_f1_image = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=10, patience=3)\n",
    "\n",
    "\n",
    "logger.info(\"Evaluating model...\")\n",
    "model.load_state_dict(torch.load(\"best_image_model.pth\"))\n",
    "val_preds_binary, val_true, best_thresholds = evaluate_model(model, val_loader)\n",
    "\n",
    "np.save(\"val_image_preds.npy\", val_preds_binary)\n",
    "np.save(\"val_image_true.npy\", val_true)\n",
    "np.save(\"image_best_thresholds.npy\", best_thresholds)\n",
    "\n",
    "hyperparams = {\n",
    "    \"model\": \"ResNet18\",\n",
    "    \"num_classes\": 19,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 10,\n",
    "    \"dropout\": 0.0,\n",
    "    \"label_smoothing\": 0.1\n",
    "}\n",
    "with open(\"image_model_hyperparams.json\", \"w\") as f:\n",
    "    json.dump(hyperparams, f)\n",
    "\n",
    "print(\"Best image model saved to best_image_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b27d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
